{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment11.ipynb","provenance":[],"private_outputs":true,"mount_file_id":"1cN2tyq1MQVd6IBU2kwfCQWhVrTa_fagx","authorship_tag":"ABX9TyMRVC0T4KEklLXWwMy/p8zh"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"tcnyYkAsB5WH","colab_type":"code","colab":{}},"source":["import numpy as np\n","import re\n","import nltk\n","from sklearn.datasets import load_files\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","import pickle\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.model_selection import train_test_split\n","\n","\n","review_data = load_files(r\"movie_review\")\n","X, y = review_data.data, review_data.target\n","\n","documents = []\n","\n","stemmer = WordNetLemmatizer()\n","\n","for sen in range(0, len(X)):\n","    # Remove all the special characters\n","    document = re.sub(r'\\W', ' ', str(X[sen]))\n","    \n","    # remove all single characters\n","    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n","    \n","    # Remove single characters from the start\n","    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n","    \n","    # Substituting multiple spaces with single space\n","    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n","    \n","    # Removing prefixed 'b'\n","    document = re.sub(r'^b\\s+', '', document)\n","    \n","    # Converting to Lowercase\n","    document = document.lower()\n","    \n","    # Lemmatization\n","    document = document.split()\n","    document = [stemmer.lemmatize(word) for word in document]\n","    document = ' '.join(document)\n","    \n","    documents.append(document)\n","\n","vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n","X = vectorizer.fit_transform(documents).toarray()\n","\n","tfidfconverter = TfidfTransformer()\n","X = tfidfconverter.fit_transform(X).toarray()\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n"],"execution_count":0,"outputs":[]}]}